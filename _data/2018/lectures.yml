-
  layout: lecture
  selected: y
  date: 2018-10-29
  img: introduction-icon_1-267x300
  uid: intro
  title: "Introduction"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "Introduction to the course"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture1.pdf
  further: 
    - "Chapter 4: [Naive Bayes classification and sentiment](https://web.stanford.edu/~jurafsky/slp3/4.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-11-01
  img: Morphology
  uid: lec2
  title: "Morphological processing"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will discuss morphological processing"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture2.pdf
  further: 
    - "Lecture notes are available [here](https://cl-illc.github.io/nlp1/resources/slides/Morphology-notes.pdf)"
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-11-05
  img: PoS
  uid: lec3
  title: "Language models and part-of-speech tagging"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will discuss language models, i.e. modelling word sequences, and part-of-speech tagging"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture3.pdf
  further: 
    - "Chapter 3: [Language modelling with n-grams](https://web.stanford.edu/~jurafsky/slp3/3.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 8: [Part-of-speech tagging](https://web.stanford.edu/~jurafsky/slp3/8.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2018-11-08
  img: Parsing
  uid: lec4
  title: "Formal grammars and syntactic parsing"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will discuss syntax and syntactic parsing"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture4.pdf
  further: 
    - "Chapter 10: [Formal grammars of English](https://web.stanford.edu/~jurafsky/slp3/10.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 11: [Syntactic parsing](https://web.stanford.edu/~jurafsky/slp3/11.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2018-11-12
  img: vectors
  uid: lec5
  title: "Lexical and distributional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will discuss lexical semantics, i.e. modelling the meaning of words, and will introduce statistical models of word meaning"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture5.pdf
  further: 
    - "Appendix Chapter C: [Computing with Word Senses: WSD and WordNet](https://web.stanford.edu/~jurafsky/slp3/C.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 6: [Vector semantics](https://web.stanford.edu/~jurafsky/slp3/6.pdf) in Jurafsky and Martin (3rd edition)."
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2018-11-15
  img: skip-gram
  uid: lec6
  title: "Distributional semantics, generalisation and word embeddings"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will discuss generalisation from words to semantic classes and learning dense vector representations - word embeddings."
  background:
  discussion:
  slides: resources/slides/NLP1-lecture6.pdf
  further: 
    - "Chapter 6: [Vector semantics](https://web.stanford.edu/~jurafsky/slp3/6.pdf) in Jurafsky and Martin (3rd edition)."
    - "A gentle introduction to neural networks can be found [here](http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/)"
  video: https://webcolleges.uva.nl/Mediasite/Play/d85ac497a6054dfb8982713d029abb211d
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2018-11-19
  img: srn
  uid: lec7
  title: "Word embeddings and sentence representations"
  instructor: "Ekaterina Shutova and Joost Bastings"
  note: 
  abstract: >
    "In this lecture, we will discuss methods for learning dense word embeddings and compositional semantics, i.e. modelling the meaning of phrases and sentences, and learning neural representations of sentences."
  background:
  discussion:
  slides: resources/slides/NLP1-lecture7.pdf
  further: 
    - "Chapter 6: [Vector semantics](https://web.stanford.edu/~jurafsky/slp3/6.pdf) in Jurafsky and Martin (3rd edition) has a section on word embeddings."
    - "Chapter 7: [Neural networks and neural language models](https://web.stanford.edu/~jurafsky/slp3/7.pdf) in Jurafsky and Martin (3rd edition)."
    - "Chapter 9: [Sequence processing with recurrent neural networks](https://web.stanford.edu/~jurafsky/slp3/9.pdf) in Jurafsky and Martin (3rd edition)."
    - "The following paper provides a nice explanation of skip-gram with negative sampling: Yoav Goldberg and Omer Levy. [word2vec Explained: Deriving Mikolov et al.â€™s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)"
    - "A good and general reference for Neural Networks in NLP: Yoav Goldberg. [A Primer on Neural Network Models for Natural Language Processing
](https://arxiv.org/abs/1510.00726)"
  video: https://webcolleges.uva.nl/Mediasite/Play/90f9539bcc17469a817d3e09ad7546a91d
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2018-11-26
  img: Discourse
  uid: lec8
  title: "Compositional semantics (continued). Discourse processing"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will finish our discussion of compositional semantics and then talk about discourse processing, i.e. modelling larger text fragments."
  background:
  discussion:
  slides: resources/slides/NLP1-lecture8.pdf
  further: 
    - "A gentle introduction to LSTMs is available [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
    - "This is one of the papers that have introduced tree LSTM models: Kai Sheng Tai, Richard Socher, and Christopher D. Manning. [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](http://aclweb.org/anthology/P/P15/P15-1150.pdf)" 
  video: https://webcolleges.uva.nl/Mediasite/Play/2af6f62c7a94499b99facda2cefaccf61d
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2018-11-29
  img: paraphrase
  uid: lec9
  title: "Textual entailment and paraphrasing"
  instructor: "Guest lecture by Miguel Rios"
  note: 
  abstract: >
    "In this lecture, we will discuss modelling textual entailment and paraphrasing methods."
  background:
  discussion:
  slides: resources/slides/NLP1-lecture9.pdf
  further: 
    - "[A Survey of Paraphrasing and Textual Entailment Methods](https://arxiv.org/pdf/0912.3747.pdf) (Sections 1 and 2)"
    - "[A large annotated corpus for learning natural language inference](https://nlp.stanford.edu/pubs/snli_paper.pdf)"
    - "[Annotation Artifacts in Natural Language Inference Data](http://aclweb.org/anthology/N18-2017)"
  video: https://webcolleges.uva.nl/Mediasite/Play/5f728f76bbec4fde97c84457ba94cdd31d
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2018-12-03
  img: dialogue
  uid: lec10
  title: "Dialogue modelling"
  instructor: "Guest lecture by Raquel Fernandez and Elia Bruni"
  note: 
  abstract: >
    "In this lecture, we will discuss dialogue modelling and dialogue systems."
  background:
  discussion:
  slides: resources/slides/NLP1-lecture10.pdf
  further: 
    - "Elia Bruni's slides are available [here](https://drive.google.com/file/d/1peqgNx0A_JQbdGDeDDsdjApcbVU8rbfl/view?usp=sharing)"
    - "Chapter 24 of Jurafsky & Martin (3rd edition): [Dialog Systems and Chatbots](https://web.stanford.edu/~jurafsky/slp3/24.pdf)"
    - "Chapter 25 of J&M (3rd ed): [Advanced Dialog Systems](https://web.stanford.edu/~jurafsky/slp3/25.pdf)"
    - "[A Survey of Available Corpora for Building Data-Driven Dialogue Systems](https://breakend.github.io/DialogDatasets/)"
    - "Section 2 of [this paper](https://arxiv.org/pdf/1512.05742.pdf) offers a concise overview of data-driven dialogue systems"
    - "[Tutorial on Deep Learning for Dialogue Systems at COLING 2018](https://sites.google.com/view/deepdial/)"
    - "[GuessWhat?! Visual object discovery through multi-modal dialogue](https://arxiv.org/abs/1611.08481)"
    - "[Visual Dialog](https://arxiv.org/abs/1611.08669)"
  code:
  video: https://webcolleges.uva.nl/Mediasite/Play/2dbad73345bb4facbf3a132691df06001d
  data:  
-
  layout: lecture
  selected: y
  date: 2018-12-06
  img: Discourse
  uid: lec11
  title: "Language generation and summarisation"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture, we will talk about language generation and cover a particular language generation task, text summarisation, in more detail."
  background:
  discussion:
  slides: resources/slides/NLP1-lecture11.pdf
  further: 
    - "A survey of recent summarisation techniques is available [here](https://arxiv.org/pdf/1804.04589.pdf)"
    - "An introduction to sequence-to-sequence models: [Sequence to Sequence Learning with Neural Networks](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)"
  video: https://webcolleges.uva.nl/Mediasite/Play/5e8d240077ed433ab05302f99d21e86f1d
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2018-12-10
  img: MT
  uid: lec12
  title: "Machine translation"
  instructor: "Joost Bastings"
  note: 
  abstract: >
    "In this lecture, we will discuss approaches to machine translation"
  background:
  discussion:
  slides: resources/slides/NLP1-lecture12.pdf
  further: 
    - "[Word based IBM models](http://www.aclweb.org/anthology/J93-2003)"
    - "[Phrase-based SMT](http://www.aclweb.org/anthology/N03-1017) and this [book](http://www.statmt.org/book/)"
    - "[Neural Encoder-Decoder](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)"
    - "[Encoder-Decoder blog post](https://bastings.github.io/annotated_encoder_decoder/)"
  video: https://webcolleges.uva.nl/Mediasite/Play/6795feb2e66c45f0979531db6b1625941d
  code: https://github.com/joeynmt/joeynmt
  data:  
-
  layout: lecture
  selected: y
  date: 2018-12-13
  img: dgm
  uid: lec13
  title: "Foundations of Bayesian NLP"
  instructor: "Guest lecture by Wilker Aziz"
  note: 
  abstract: >
    "In this lecture, we will discuss Bayesian modelling in NLP"
  background:
  discussion:
  slides: 
  further: 
  video: 
  code: 
  data:  
